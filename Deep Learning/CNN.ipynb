{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecdbcffa",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) \n",
    "\n",
    "## Overview\n",
    "This project implements a **Convolutional Neural Network (CNN)** using **TensorFlow and Keras** to classify images of **cats and dogs**.  \n",
    "The workflow is divided into 4 main parts:\n",
    "1. **Data Preprocessing** → Prepare training and test images.  \n",
    "2. **Building the CNN** → Define layers of the neural network.  \n",
    "3. **Training the CNN** → Compile and fit the model.  \n",
    "4. **Making Predictions** → Test the trained model on new images.  \n",
    "\n",
    "CNNs are powerful because they use **convolution + pooling** to automatically extract features from images (edges, textures, shapes), making them well-suited for image classification tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1 - Data Preprocessing\n",
    "\n",
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9196433d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\Users\\makmo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\makmo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39m__version__)\n",
      "File \u001b[1;32mc:\\Users\\makmo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32mc:\\Users\\makmo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[0m\n\u001b[0;32m     86\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     94\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\Users\\makmo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b37122",
   "metadata": {},
   "source": [
    "- tensorflow → Main deep learning framework.\n",
    "- ImageDataGenerator → Helps preprocess and augment image datasets.\n",
    "- tf.__version__ → Shows installed TensorFlow version.\n",
    "\n",
    "# Preprocessing the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'dataset/training_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f05fd0",
   "metadata": {},
   "source": [
    "- rescale=1./255 → Normalizes pixel values (0–255 → 0–1).\n",
    "- shear_range=0.2 → Random shear for augmentation.\n",
    "- zoom_range=0.2 → Random zoom.\n",
    "- horizontal_flip=True → Flips images horizontally.\n",
    "- target_size=(64,64) → Resizes images to 64x64.\n",
    "- batch_size=32 → Number of images per batch.\n",
    "- class_mode='binary' → Since we have two classes (cat/dog).\n",
    "\n",
    "## Preprocessing the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bbffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'dataset/test_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be4c999",
   "metadata": {},
   "source": [
    "- Only rescaling applied → No augmentation (to keep test set realistic).\n",
    "\n",
    "## Part 2 - Building the CNN\n",
    "\n",
    "### Initializing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddf00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27bd8d",
   "metadata": {},
   "source": [
    "- Sequential() → Stack layers step by step.\n",
    "\n",
    "### Step 1: Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    activation='relu',\n",
    "    input_shape=[64, 64, 3]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658558f5",
   "metadata": {},
   "source": [
    "- filters=32 → Number of feature detectors.\n",
    "- kernel_size=3 → 3x3 filter size.\n",
    "- activation='relu' → ReLU introduces non-linearity.\n",
    "- input_shape=[64,64,3] → Image size + 3 channels (RGB).\n",
    "\n",
    "### Step 2: Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d01ee0",
   "metadata": {},
   "source": [
    "- pool_size=2 → Reduces image dimension by 2x2 blocks.\n",
    "- strides=2 → Moves filter by 2 pixels.\n",
    "- Helps reduce computation & extract important features.\n",
    "\n",
    "### Adding Another Convolution + Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119acb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bbfe8d",
   "metadata": {},
   "source": [
    "- Adding a second convolutional layer improves feature extraction.\n",
    "\n",
    "### Step 3: Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeefe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80263144",
   "metadata": {},
   "source": [
    "- Converts 2D feature maps → 1D vector.\n",
    "- Prepares data for fully connected layers.\n",
    "\n",
    "### Step 4: Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c19e603",
   "metadata": {},
   "source": [
    "- Dense → Fully connected layer.\n",
    "- units=128 → Number of neurons.\n",
    "- relu → Adds non-linearity to learn complex patterns.\n",
    "\n",
    "### Step 5: Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9880a5",
   "metadata": {},
   "source": [
    "- units=1 → Since binary classification (cat vs dog).\n",
    "- sigmoid → Outputs probability (0 = cat, 1 = dog).\n",
    "\n",
    "## Part 3 - Training the CNN\n",
    "\n",
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5360fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f41f0b",
   "metadata": {},
   "source": [
    "- optimizer='adam' → Adaptive optimizer for learning.\n",
    "- loss='binary_crossentropy' → For binary classification.\n",
    "- metrics=['accuracy'] → Tracks accuracy during training.\n",
    "\n",
    "### Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef59ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e831f258",
   "metadata": {},
   "source": [
    "- x=training_set → Training data.\n",
    "- validation_data=test_set → Validation for model performance.\n",
    "- epochs=25 → Number of training iterations.\n",
    "\n",
    "### Part 4 - Making a Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e02d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd80e14",
   "metadata": {},
   "source": [
    "- load_img() → Loads the image and resizes.\n",
    "- img_to_array() → Converts image → NumPy array.\n",
    "- expand_dims() → Adds batch dimension.\n",
    "- cnn.predict() → Outputs probability.\n",
    "\n",
    "### Interpreting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c001e",
   "metadata": {},
   "source": [
    "- If output close to 1 → dog, else cat.\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- CNN automatically extracts features (edges, shapes, textures).\n",
    "- With convolution + pooling, the model learns image features.\n",
    "- Fully connected layers perform classification.\n",
    "- Trained CNN can predict unseen images of cats/dogs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
